Google’s mission is to organize the world’s information and make it universally accessible and useful. Google Search has become a shining example of progress towards accomplishing this mission. 

Google Search is the best general-purpose search engine and it gets better all the time. Over the years it killed off most of it’s competitors.

Since Yahoo Search is powered by Bing the there’s really only four general-purpose search engines  -Google, Bing, Yandex and Baidu.

While there are a few smaller players in general-purpose search market such as Ask, DuckDuckGo, Blekko, it is hard to see how they will ever grow to overtake Google Search.

With this in mind, I would like to offer what may be a counter-intuitive idea: now more than ever it is possible to compete and win against Google Search. To see it, we need to look at the technology and the market from a different perspective.

A 2013  study by Incapsula highlighted that over 61% of the web traffic is generated by bots. There are more types of crawlers and they crawl more frequently. Some of the bots are malicious, but the bulk of non-human traffic is attributed to all sorts of different web crawlers.

Bots make up over 61% of the traffic. Just non-malicious crawlers alone generate more traffic than people.

What is behind such huge growth? The most logical answer is, there’s a growing set of services that (to use Google’s mission statement) organize world’s information to make it more accessible and useful. This finding is, of course, a complete contradiction to the conventional view that Web Search innovation have ended and that Google has won. The fact is, there’s growing number of successful Web Search Engines out-there.

Search engines are everywhere To see just how prevalent those web search engines are we need to look at specific industries, specific use-cases, specific domains of knowledge.

Here are just a few examples of domain-specific search engines.

Yelp is a search engine that combines web and other data sources

At it’s core, Yelp is a search engine that indexes a specific dataset of business information, reviews and photos. It’s ranking algorithms are tuned to look at geo-location, sentiment of the review, availability of photos, etc.

TripAdvisor is the kind of search engine that relies on user comments

TripAdvisor is a search engine that also indexes multiple different sources of information. Just like Yelp, web isn’t the only source of it’s data. Its ranking algorithms rely on comments in a big way. The ranking on TripAdvisor is affected by quality, quantity and recency of comments authored by their users.





Shopping.com is a great example of a large class of e-commerce web search engines.

Shopping.com is one of many e-commerce search engines that use the web as the primary source of content they index. The structure of the content and their ranking algorithms are optimized to return the most relevant product and help shoppers click though other related products.








WebMD organizes medical knowledge from the web and applies a heavy doze of expert curation to make sure the content they index is accurate. Of course the ranking algorithms take into account semantics of the medical field such as relationships between symptoms and diseases.

There are numerous other examples of search engines that organize information in a specific domain, or as they are commonly known, vertical search engines. 

Radialpoint is also building a search engine. We’re building one for consumer tech support.

Radialpoint Reveal Reveal is a browser extension that improves Google search for tech support agents. 

Take a Netflix user who can’t stream & calls for support. Is the issue related to Netflix, XBox where the app is running, the Samsung TV, the Linksys wifi router, or the Comcast Internet connection?

Most support agents routinely use Google search along with their internal knowledge base. Yet, Google’s results are neither validated nor ranked based on the needs of tech support use-case. 

Being a general-purpose search engine, Google does not understand the semantics of a technical support problem. And just like in travel, health or e-commerce, understanding of semantics and context is essential to effective search.

Reveal is the first Radialpoint product we’re building that incorporates a search engine (we’re just getting started!). When building Reveal we use a strategy that is very applicable to any vertical semantic search engine. 

Building a vertical search engine At the highest level, vertical search engines have three big challenges in common.

First is getting raw content. Unlike general-purpose engines like Google and Bing, vertical search engines need to organize a specific portion of the web and possibly include other sources of content beyond the Web. Filtering the Web is a challenge. The system will need to crawl the subset of the Web without actually having access to the entire Web. One of the resources that helps if CommonCrawl. Common Crawl builds and maintains on open crawl of the Web that can be accessed and analyzed by everyone.

At Radialpoint, we’re using CommonCrawl as a starting point, to find the most relevant parts of the web — tech support forums, knowledge bases, troubleshooting blog posts, etc. — and then keep it current by targeted crawling.

Once the raw content is available, the second challenge is to structure it. Vertical search engine can and should leverage the semantics and the structure of a given knowledge domain. This is the key reason why a vertical search engine can compete with general-purpose search engine. In Radialpoint’s case we want to extract entities like devices and services, to capture the relationship between Xbox and Netflix entities.

When the most relevant content is structured and organized using semantics of a given vertical, a search engine needs to be able to process user’s query, to understand its intent and to add all available context. In our example, when the users says “I cannot watch Netflix on my TV” a search engine designed for tech support should know that a use-case of streaming a movie requires working internet connectivity.





To sum up, the way to compete against Google is not to go build another general-purpose search engine. It is to build another vertical semantic search engine. Because such engines understand the specific semantcs of a given domain, they have a very good chance to be better than Google search. This is why we’re seeing such a strong growth of vertical search engines.